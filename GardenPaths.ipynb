{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('691DD': conda)"
  },
  "interpreter": {
   "hash": "07de30308711806ec6062f7254ded7134ae2bc160a01411f26624d89ff5a5026"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForMaskedLM\n",
    "import numpy as np\n",
    "import torch\n",
    "from pprint import pprint\n",
    "import logging\n",
    "import re\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "def print_header(header):\n",
    "    print(\"\\n\\n----------------------------------------------------------\")\n",
    "    print(header)\n",
    "    print(\"----------------------------------------------------------\")\n",
    "\n",
    "models = {\n",
    "    # 'BERT': 'bert-base-uncased',\n",
    "    'BERT (whole word)': 'bert-large-uncased-whole-word-masking',\n",
    "    'GPT': 'gpt2',\n",
    "}\n",
    "\n",
    "sentence_dict = [\n",
    "    {\n",
    "        'sentences': [\n",
    "            \"The horse raced past the barn [MASK]\",\n",
    "            # \"The horse raced past the barn [MASK].\"\n",
    "            ],\n",
    "        'fillers': [\n",
    "            'fell',\n",
    "            'is',\n",
    "            'was',\n",
    "            'and',\n",
    "            '.',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'sentences': [\n",
    "            \"The butter melted in the pan [MASK]\",\n",
    "            # \"The butter melted in the pan [MASK].\",\n",
    "        ],\n",
    "        'fillers': [\n",
    "            'smelled',\n",
    "            'smells',\n",
    "            'is',\n",
    "            'was',\n",
    "            'and',\n",
    "            '.',\n",
    "        ]\n",
    "    }\n",
    "]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Behavior Exploration -- BERT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def setup(model):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(models[model])\n",
    "    model = AutoModelForMaskedLM.from_pretrained(models[model])\n",
    "    bert = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "    mask = bert.tokenizer.mask_token\n",
    "    return bert, mask\n",
    "\n",
    "def runBERT(sentence_dict):\n",
    "    bert, mask = setup('BERT (whole word)')\n",
    "    filler_results = {}\n",
    "    top_preds = {}\n",
    "    for sentence_type in sentence_dict:\n",
    "        for sentence in sentence_type['sentences']:\n",
    "            # sentence = sentence.replace(\"[MASK]\", mask)\n",
    "            filler_results[sentence] = {}\n",
    "            outputs = bert(sentence, top_k=12)\n",
    "            top_preds[sentence] = [(output[\"token_str\"], output['score']) for output in outputs]\n",
    "            for filler in sentence_type['fillers']:\n",
    "                filler_results[sentence][filler] = bert(sentence, targets=[filler])[0][\"score\"]\n",
    "    return filler_results, top_preds\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "filler_results, top_preds = runBERT(sentence_dict)\n",
    "\n",
    "print_header('Filler Results')\n",
    "pprint(filler_results, sort_dicts=False)\n",
    "\n",
    "print_header('Model Predictions')\n",
    "pprint(top_preds, sort_dicts=False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------------------\n",
      "Filler Results\n",
      "----------------------------------------------------------\n",
      "{'The horse raced past the barn [MASK]': {'fell': 1.0337573463914396e-08,\n",
      "                                          'is': 5.357605559197509e-08,\n",
      "                                          'was': 3.807201380823244e-07,\n",
      "                                          'and': 0.00020737976592499763,\n",
      "                                          '.': 0.9778836965560913},\n",
      " 'The butter melted in the pan [MASK]': {'smelled': 7.43062429364727e-08,\n",
      "                                         'smells': 2.818679689653436e-08,\n",
      "                                         'is': 1.2275096139546804e-07,\n",
      "                                         'was': 7.456794151039503e-07,\n",
      "                                         'and': 0.00023132975911721587,\n",
      "                                         '.': 0.9349180459976196}}\n",
      "\n",
      "\n",
      "----------------------------------------------------------\n",
      "Model Predictions\n",
      "----------------------------------------------------------\n",
      "{'The horse raced past the barn [MASK]': [('.', 0.9778836965560913),\n",
      "                                          (';', 0.020293451845645905),\n",
      "                                          ('!', 0.0006812851643189788),\n",
      "                                          (',', 0.0004022846114821732),\n",
      "                                          ('and', 0.00020737976592499763),\n",
      "                                          ('?', 8.586062176618725e-05),\n",
      "                                          ('as', 5.665285425493494e-05),\n",
      "                                          (':', 5.4496078519150615e-05),\n",
      "                                          ('...', 4.590198659570888e-05),\n",
      "                                          ('with', 2.4866461899364367e-05),\n",
      "                                          ('-', 1.37587030621944e-05),\n",
      "                                          ('to', 9.849945854512043e-06)],\n",
      " 'The butter melted in the pan [MASK]': [('.', 0.9349180459976196),\n",
      "                                         (';', 0.06335761398077011),\n",
      "                                         ('!', 0.000741223047953099),\n",
      "                                         (',', 0.0002796006156131625),\n",
      "                                         ('and', 0.00023132975911721587),\n",
      "                                         ('?', 0.00017703276535030454),\n",
      "                                         (':', 6.492900138255209e-05),\n",
      "                                         ('...', 3.9007834857329726e-05),\n",
      "                                         ('as', 3.372329592821188e-05),\n",
      "                                         ('so', 1.0385915629740339e-05),\n",
      "                                         ('*', 8.833228093863e-06),\n",
      "                                         ('until', 6.925132765900344e-06)]}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Behavior Exploration -- GPT2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np \n",
    "\n",
    "def score(model, tokens_tensor):\n",
    "    loss=model(tokens_tensor, labels=tokens_tensor)[0]\n",
    "    return np.exp(loss.cpu().detach().numpy())\n",
    "\n",
    "def runGPT(sentence_dict):\n",
    "    model = GPT2LMHeadModel.from_pretrained(models['GPT'])\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(models['GPT'])\n",
    "    filler_results = {}\n",
    "    top_preds = {}\n",
    "    model.eval()\n",
    "    for sentence_type in sentence_dict:\n",
    "        for sentence in sentence_type['sentences']:\n",
    "            # text = sentence.replace('[MASK]', '')\n",
    "            # with torch.no_grad():\n",
    "                # outputs = model(tokenizer.encode(text, add_special_tokens=False, return_tensors=\"pt\"))\n",
    "                # predictions = outputs[0][0, -1, :]\n",
    "                # print(len(predictions))\n",
    "                # print([tokenizer.decode([pred.item()]) for pred in predictions])\n",
    "\n",
    "            # next_token_logits = outputs[0]\n",
    "            # print(next_token_logits)\n",
    "            \n",
    "            filler_results[sentence] = {}\n",
    "            for filler in sentence_type['fillers']:\n",
    "                tokens_tensor = tokenizer.encode(sentence.replace('[MASK]', filler), add_special_tokens=False, return_tensors=\"pt\")\n",
    "                filler_results[sentence][filler] = score(model, tokens_tensor)\n",
    "    return filler_results, top_preds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "filler_results, top_preds = runGPT(sentence_dict)\n",
    "print_header(\"Filler Results\")\n",
    "pprint(filler_results, sort_dicts=False)\n",
    "print_header(\"Model Predictions\")\n",
    "pprint(top_preds, sort_dicts=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------------------\n",
      "Filler Results\n",
      "----------------------------------------------------------\n",
      "{'The horse raced past the barn [MASK]': {'fell': 721.4816,\n",
      "                                          'is': 333.83664,\n",
      "                                          'was': 323.6483,\n",
      "                                          'and': 109.708084,\n",
      "                                          '.': 486.77307},\n",
      " 'The butter melted in the pan [MASK]': {'smelled': 362.05237,\n",
      "                                         'smells': 339.34354,\n",
      "                                         'is': 128.78635,\n",
      "                                         'was': 131.93286,\n",
      "                                         'and': 53.049614,\n",
      "                                         '.': 159.93929}}\n",
      "\n",
      "\n",
      "----------------------------------------------------------\n",
      "Model Predictions\n",
      "----------------------------------------------------------\n",
      "{}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}